{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UyEb1WYm2A4H","executionInfo":{"status":"ok","timestamp":1739860728812,"user_tz":480,"elapsed":2210,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"e5c5a233-615e-4ee4-d87c-25fd686acb59"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","%cd \"/content/drive/MyDrive/VideoSeal-main\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSUuY4Oy2Iw6","executionInfo":{"status":"ok","timestamp":1739861226610,"user_tz":480,"elapsed":170,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"28fe712a-ebb0-4187-f541-d042400d0060"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1vs99Ljy_X3Wg-u5WtsXQkNH4AV1wpXk5/VideoSeal-main\n"]}]},{"cell_type":"code","source":["!pip3 install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VSLXZJXg2UzM","executionInfo":{"status":"ok","timestamp":1739860733950,"user_tz":480,"elapsed":2269,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"3ad7c325-7b45-48b1-a554-79723ceff752"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.11.0.86)\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.3.0)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.8.1)\n","Requirement already satisfied: lpips in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.1.4)\n","Requirement already satisfied: timm==0.9.16 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.9.16)\n","Requirement already satisfied: pre-commit in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.1.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (5.5.6)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.0.8)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.8.0)\n","Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (14.1.0)\n","Requirement already satisfied: pyav in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (14.1.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (4.67.1)\n","Requirement already satisfied: pytorch_msssim in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (1.0.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.18.0)\n","Requirement already satisfied: calflops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.3.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (4.48.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (1.13.1)\n","Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.2.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (2.5.1+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (0.20.1+cu124)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (0.28.1)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 3)) (4.9.3)\n","Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (3.4.0)\n","Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (2.6.7)\n","Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (1.9.1)\n","Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (20.29.2)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.4.2)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools->-r requirements.txt (line 9)) (3.10.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 14)) (3.4.2)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 14)) (11.1.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 14)) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 14)) (2025.1.10)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 14)) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 14)) (0.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (1.70.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (4.25.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 18)) (3.1.3)\n","Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from calflops->-r requirements.txt (line 19)) (1.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 20)) (3.17.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 20)) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 20)) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 20)) (0.21.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r requirements.txt (line 27)) (1.0.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.22.0->calflops->-r requirements.txt (line 19)) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16->-r requirements.txt (line 6)) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16->-r requirements.txt (line 6)) (4.12.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (3.0.50)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (4.9.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (3.1.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm==0.9.16->-r requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 7)) (0.3.9)\n","Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 7)) (4.3.6)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 18)) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 8)) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 8)) (24.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 20)) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 20)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 20)) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 20)) (2025.1.31)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->-r requirements.txt (line 8)) (0.2.13)\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zOYiObrX1-WR","executionInfo":{"status":"ok","timestamp":1739860749566,"user_tz":480,"elapsed":3770,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","import logging\n","logging.getLogger(\"matplotlib.image\").setLevel(logging.ERROR)\n","from IPython.display import HTML, display\n","\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import torch\n","import torchvision\n","import torchvision.transforms.functional as F\n","\n","# import videoseal\n","# from videoseal.augmentation import H264\n","# from videoseal.evals.metrics import bit_accuracy\n","from videoseal.evals.metrics import bit_accuracy\n","from videoseal.models import Videoseal\n","from videoseal.utils.cfg import setup_model_from_model_card\n","\n","import argparse\n","import cv2\n","import numpy as np"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"U_w0Bn5N1-WT","executionInfo":{"status":"ok","timestamp":1739860749567,"user_tz":480,"elapsed":2,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}}},"outputs":[],"source":["def save_torch_video(video_w, out_path, fps):\n","    numpy_vid = torch.permute(video_w, (0, 2, 3, 1)).detach().numpy()\n","    numpy_vid = (numpy_vid * 255).astype(np.uint8)\n","\n","    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (numpy_vid.shape[2], numpy_vid.shape[1]))\n","    cv2.imwrite(\"test_frame.png\", numpy_vid[0])\n","    for i in range(numpy_vid.shape[0]):\n","        numpy_vid[i] = cv2.cvtColor(numpy_vid[i], cv2.COLOR_BGR2RGB)\n","        out.write(numpy_vid[i])\n","\n","    out.release()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"o_y2a4_C1-WT","executionInfo":{"status":"ok","timestamp":1739860749567,"user_tz":480,"elapsed":1,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}}},"outputs":[],"source":["def pgd_attack(model, img, target_labels, alpha=0.007, eps=0.03, num_iter=20):\n","    bce_loss = torch.nn.BCEWithLogitsLoss()\n","    img_original = img.clone()\n","    for i in range(num_iter):\n","        img.retain_grad()\n","        detection = model.detect(torch.unsqueeze(img, dim=0), is_video=False)['preds']\n","        total_ce_loss = bce_loss(torch.squeeze(detection)[1:], torch.squeeze(target_labels.float()))\n","        total_ce_loss.backward(retain_graph=True)\n","        with torch.no_grad():\n","            grad_sign = torch.sign(img.grad)\n","            img -= alpha * grad_sign\n","            img = torch.clamp(img, min=img_original - eps, max=img_original + eps)\n","            img = torch.clamp(img, min=0, max=1)\n","        img.requires_grad = True\n","        img.grad = None\n","        model.grad = None\n","        total_ce_loss = 0\n","        torch.cuda.empty_cache()\n","    #print((detection > 0).int())\n","    return img.detach().cpu()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"MewrToLm1-WU","executionInfo":{"status":"ok","timestamp":1739860749567,"user_tz":480,"elapsed":1,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}}},"outputs":[],"source":["def final_message_extractor(msg_path, video_path, model):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    gt_msgs = torch.tensor(np.loadtxt(msg_path))\n","\n","    video_w, _, _ = torchvision.io.read_video(video_path, output_format=\"TCHW\")\n","    video_w = video_w.to(device)\n","    video_w = video_w / 255.0\n","    video_w = video_w[:50]\n","    with torch.no_grad():\n","        msg_extracted = model.extract_message(video_w, None).cpu().detach()\n","        bit_accuracy_ = bit_accuracy(msg_extracted, gt_msgs).nanmean().item()\n","        print(f\"Bit Accuracy: {bit_accuracy_:.3f}\")\n","        print(\"GT:\", gt_msgs[0])\n","        print(\"Extracted\", msg_extracted.int())"]},{"cell_type":"code","source":["def videoseal_eval(video_name, model):\n","  # Read the video and convert to tensor format\n","  video, _, _ = torchvision.io.read_video(video_name + \".mp4\", output_format=\"TCHW\", pts_unit='sec', end_pts=6)\n","\n","  # Normalize the video frames to the range [0, 1] and trim to 1 second\n","  video = video.float() / 255.0\n","  #video = video[:, :, :500, :500]\n","  video = video.to(device)\n","  # Perform watermark embedding\n","  gt_msgs = torch.zeros(1, 96)\n","  with torch.no_grad():\n","      outputs = model.embed(video, is_video=True, msgs=gt_msgs.to(device))\n","  # Extract the results\n","  video_w = outputs[\"imgs_w\"].cpu().detach()  # Watermarked video frames\n","\n","  save_torch_video(video_w, video_name + '_w.mp4', fps)\n","\n","  np.savetxt('./assets/videos/1_msgs.txt', gt_msgs, fmt='%d')\n","  # Delete variables to preserve GPU memory\n","  del outputs\n","  del video_w\n","  del video\n","  torch.cuda.empty_cache()\n","  video_w, _, _ = torchvision.io.read_video(video_name + '_w.mp4', output_format=\"TCHW\")\n","  video_w = video_w / 255.0\n","  #video_w = video_w[:, :, :400, :400]\n","  video_w = video_w.to(device)\n","  video_w.requires_grad = True\n","\n","  # Get PGD attacked video\n","  video_pgd = []\n","  for i in range(video_w.shape[0]):\n","      #gt_labels = (torch.rand_like(gt_msgs) > 0).int()\n","      gt_labels = 1 - gt_msgs.to(device)\n","      video_pgd.append(pgd_attack(model, video_w[i], target_labels=gt_labels))\n","      torch.cuda.empty_cache()\n","\n","\n","  video_pgd = torch.stack(video_pgd, axis=0)\n","  save_torch_video(video_pgd, video_name + '_w_pwd.mp4', fps)\n","\n","  with torch.no_grad():\n","      final_message_extractor('./assets/videos/1_msgs.txt', video_name + '_w.mp4', model)\n","      final_message_extractor('./assets/videos/1_msgs.txt', video_name + '_w_pwd.mp4', model)"],"metadata":{"id":"UE0_2bhLP1Iy","executionInfo":{"status":"ok","timestamp":1739861271729,"user_tz":480,"elapsed":115,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["videoseal_eval('./assets/videos/static_short', model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B53Q0KfEQU7p","executionInfo":{"status":"ok","timestamp":1739854118897,"user_tz":480,"elapsed":40485,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"917b318f-3d66-4be7-8045-27e3f315964c"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Bit Accuracy: 0.775\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 0, 0,  ..., 0, 1, 0],\n","         [0, 0, 0,  ..., 0, 1, 0],\n","         [0, 0, 0,  ..., 0, 1, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 1, 0],\n","         [0, 0, 0,  ..., 0, 1, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32)\n","Bit Accuracy: 0.102\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1]]], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["videoseal_eval('./assets/videos/static_short_2', model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqHMcp6sRdm7","executionInfo":{"status":"ok","timestamp":1739855568084,"user_tz":480,"elapsed":31244,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"75cebeb3-cf58-4d97-ca48-13cf6f786816"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Bit Accuracy: 0.890\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 0, 0,  ..., 0, 1, 0],\n","         [0, 0, 0,  ..., 0, 1, 0],\n","         [0, 0, 0,  ..., 0, 1, 0],\n","         ...,\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 1, 0]]], dtype=torch.int32)\n","Bit Accuracy: 0.107\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 1, 1,  ..., 0, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1]]], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["videoseal_eval('./assets/videos/static_short_3', model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5oGPaP0Vvi9","executionInfo":{"status":"ok","timestamp":1739855601661,"user_tz":480,"elapsed":33578,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"4a8ef3fe-179c-4204-8ba1-177df9ec3c19"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Bit Accuracy: 0.904\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32)\n","Bit Accuracy: 0.127\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1]]], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["videoseal_eval('./assets/videos/moving_short', model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGjEzAeZRd4I","executionInfo":{"status":"ok","timestamp":1739861695935,"user_tz":480,"elapsed":233707,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"77667a31-a2d8-4142-d4c0-b85730280563"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Bit Accuracy: 0.872\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32)\n","Bit Accuracy: 0.113\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 0, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1]]], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["videoseal_eval('./assets/videos/moving_short_2', model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQpfTpXQReBh","executionInfo":{"status":"ok","timestamp":1739855680258,"user_tz":480,"elapsed":39180,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"e0a69e0b-e63e-42bf-e431-177800155be2"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Bit Accuracy: 0.889\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 0, 0,  ..., 0, 1, 1],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32)\n","Bit Accuracy: 0.117\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 1, 1,  ..., 1, 1, 1],\n","         [0, 0, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [0, 1, 1,  ..., 0, 1, 1],\n","         [0, 0, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1]]], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["videoseal_eval('./assets/videos/moving_short_3', model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rlmNSSVVywN","executionInfo":{"status":"ok","timestamp":1739861462229,"user_tz":480,"elapsed":185287,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"4360c612-a35b-4540-8180-c1402ba9a305"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Bit Accuracy: 0.875\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 1, 0,  ..., 0, 1, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [1, 1, 0,  ..., 0, 1, 0]]], dtype=torch.int32)\n","Bit Accuracy: 0.119\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[[1, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         [0, 1, 1,  ..., 1, 1, 1],\n","         [0, 0, 1,  ..., 1, 1, 1]]], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","fps = 24\n","\n","# Load the VideoSeal model\n","model = setup_model_from_model_card(\"videoseal\")\n","model.chunk_size=2\n","\n","# Set the model to evaluation mode and move it to the selected device\n","model = model.eval()\n","model = model.to(device)\n","\n","# Path to the input video\n","# video_name = './assets/videos/static_short'\n","# # Read the video and convert to tensor format\n","# video, _, _ = torchvision.io.read_video(video_name + \".mp4\", output_format=\"TCHW\", pts_unit='sec', end_pts=5)\n","\n","# # Normalize the video frames to the range [0, 1] and trim to 1 second\n","# video = video.float() / 255.0\n","# video = video[:30, :, :500, :500]\n","# video = video.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602},"id":"XHljl7HL45j1","executionInfo":{"status":"error","timestamp":1739860876722,"user_tz":480,"elapsed":3019,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"bc5952ac-33a7-42fd-bba7-5424171fc9ad"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","Model loaded successfully from /root/.cache/huggingface/hub/models--facebook--video_seal/snapshots/8037ef59ba2b2ec8fb8b55298ff37b8ccddd078d/checkpoint.pth with message: <All keys matched successfully>\n"]},{"output_type":"error","ename":"AttributeError","evalue":"module 'av' has no attribute 'AVError'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/io/video.py\u001b[0m in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit, output_format)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mav/container/core.pyx\u001b[0m in \u001b[0;36mav.container.core.open\u001b[0;34m()\u001b[0m\n","\u001b[0;32mav/container/core.pyx\u001b[0m in \u001b[0;36mav.container.core.Container.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mav/container/core.pyx\u001b[0m in \u001b[0;36mav.container.core.Container.err_check\u001b[0;34m()\u001b[0m\n","\u001b[0;32mav/error.pyx\u001b[0m in \u001b[0;36mav.error.err_check\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './assets/videos/static_short.mp4'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-f3fe1cae55d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mvideo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./assets/videos/static_short'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Read the video and convert to tensor format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TCHW\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_pts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Normalize the video frames to the range [0, 1] and trim to 1 second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/io/video.py\u001b[0m in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit, output_format)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audio_fps\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAVError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0;31m# TODO raise a warning?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'av' has no attribute 'AVError'"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"R1d1DeOl1-WU","executionInfo":{"status":"ok","timestamp":1739850770629,"user_tz":480,"elapsed":2410,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}}},"outputs":[],"source":["\n","# Perform watermark embedding\n","gt_msgs = torch.zeros(1, 96)\n","with torch.no_grad():\n","    outputs = model.embed(video, is_video=True, msgs=gt_msgs.to(device))\n","# Extract the results\n","video_w = outputs[\"imgs_w\"].cpu().detach()  # Watermarked video frames\n","\n","save_torch_video(video_w, video_name + '_w.mp4', fps)\n","\n","np.savetxt('./assets/videos/1_msgs.txt', gt_msgs, fmt='%d')\n","# Delete variables to preserve GPU memory\n","del outputs\n","del video_w\n","del video\n","torch.cuda.empty_cache()\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0w01Gf71-WU","executionInfo":{"status":"ok","timestamp":1739850924371,"user_tz":480,"elapsed":38420,"user":{"displayName":"AADHIDHYA RAVIKUMAR","userId":"00202980091746612025"}},"outputId":"ebc48249-fb7a-4e6a-9fff-2c6800f77be6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/io/video.py:169: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n","/usr/local/lib/python3.11/dist-packages/torchvision/io/video.py:169: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n","/usr/local/lib/python3.11/dist-packages/torchvision/io/video.py:169: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"]},{"output_type":"stream","name":"stdout","text":["Bit Accuracy: 0.625\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n","         0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n","         1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n","         0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]],\n","       dtype=torch.int32)\n","Bit Accuracy: 0.062\n","GT: tensor(0., dtype=torch.float64)\n","Extracted tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n","       dtype=torch.int32)\n"]}],"source":["video_w, _, _ = torchvision.io.read_video(video_name + '_w.mp4', output_format=\"TCHW\")\n","video_w = video_w / 255.0\n","#video_w = video_w[:, :, :400, :400]\n","video_w = video_w.to(device)\n","video_w.requires_grad = True\n","\n","# Get PGD attacked video\n","video_pgd = []\n","for i in range(video_w.shape[0]):\n","    #gt_labels = (torch.rand_like(gt_msgs) > 0).int()\n","    gt_labels = 1 - gt_msgs.to(device)\n","    video_pgd.append(pgd_attack(model, video_w[i], target_labels=gt_labels))\n","    torch.cuda.empty_cache()\n","\n","\n","video_pgd = torch.stack(video_pgd, axis=0)\n","save_torch_video(video_pgd, video_name + '_w_pwd.mp4', fps)\n","\n","with torch.no_grad():\n","    final_message_extractor('./assets/videos/1_msgs.txt', video_name + '_w.mp4', model)\n","    final_message_extractor('./assets/videos/1_msgs.txt', video_name + '_w_pwd.mp4', model)"]},{"cell_type":"code","source":[],"metadata":{"id":"kH8XbZtNPzEX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qNBA9f1OMaqK"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}